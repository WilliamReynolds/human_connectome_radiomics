{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08802bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, pickle\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import textwrap\n",
    "\n",
    "code_dir = '/'.join(os.getcwd().split('/')[:-1])\n",
    "main_code = os.path.join(code_dir, 'main_code')\n",
    "sys.path.append(main_code)\n",
    "\n",
    "import matplotlib.colors as mcol\n",
    "import matplotlib.cm as cm\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model_class import model, model_results\n",
    "import plotting_methods as pm\n",
    "import model_methods as mm\n",
    "\n",
    "\n",
    "# machine leanring methods\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# my methods \n",
    "import locations\n",
    "import general_methods\n",
    "import df_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacb564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a470d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(run_name, clf, test_x, test_y, ret_type = None):\n",
    "    #test_y = test_y+1\n",
    "    predict_y = clf.best_estimator_.predict(test_x)\n",
    "    acc = metrics.accuracy_score(predict_y, test_y)\n",
    "    f1 = metrics.f1_score(predict_y, test_y, average = 'weighted')\n",
    "    recall = metrics.recall_score(predict_y, test_y, average = 'weighted', zero_division = 0)\n",
    "    precision = metrics.precision_score(predict_y, test_y.tolist(), average = 'weighted', zero_division = 0)\n",
    "    auroc = clf.best_score_\n",
    "    \n",
    "    if ret_type == None:\n",
    "        return acc, f1, recall, precision  \n",
    "    if ret_type.lower() == 'dict':\n",
    "        return {'run_name': run_name, 'accuracy':acc, 'f1': f1, 'recall':recall, 'precision':precision, 'auroc': auroc}\n",
    "    if ret_type.lower() == 'list':\n",
    "        return [acc, f1, recall, precision]\n",
    "    \n",
    "def build_df(res_dict):\n",
    "    res_df = pd.DataFrame(columns = ['df_type', 'phrase', 'model_method', 'runtime'])\n",
    "    for k,v in res_dict.items():\n",
    "        df_type, phrase, model_method, clf, runtime, test_x, test_y = v\n",
    "        row_dict = {'df_type': df_type, 'phrase':phrase, 'model_method':model_method, 'runtime':runtime}\n",
    "        row = pd.Series(row_dict).to_frame().T\n",
    "        res_df = pd.concat([res_df, row], ignore_index = True, axis = 0)\n",
    "    return res_df\n",
    "\n",
    "def find_entry(model_id):\n",
    "    run_name = combine_df.loc[combine_df.loc[:,'model_id'] == model_id, 'run_name'].values.item()\n",
    "    for k,v in merge_dict.items():\n",
    "        if k == run_name:\n",
    "            return k, v \n",
    "        \n",
    "def pickle_exists():\n",
    "    save_dir = locations.get_locations('save_dir')\n",
    "    save_date = locations.get_locations('save_date')\n",
    "    pkl_name = f'{save_date}_model_results.pkl'   \n",
    "    load_pickle_path = os.path.join(save_dir, pkl_name)\n",
    "    return os.path.isfile(load_pickle_path)\n",
    "    \n",
    "    \n",
    "def load_pickle():\n",
    "    save_dir = locations.get_locations('save_dir')\n",
    "    save_date = locations.get_locations('save_date')\n",
    "    pkl_name = f'{save_date}_model_results.pkl'\n",
    "    load_pickle_path = os.path.join(save_dir, pkl_name)\n",
    "    if pickle_exists():\n",
    "        with open(load_pickle_path, 'rb') as f:\n",
    "            model_list = pickle.load(f)\n",
    "    return model_list\n",
    "\n",
    "\n",
    "def save_pickle(res_list):\n",
    "    save_dir = locations.get_locations('save_dir')\n",
    "    save_date = locations.get_locations('save_date')\n",
    "    pkl_name = f'{save_date}_model_results.pkl'\n",
    "    save_pickle_path = os.path.join(save_dir, pkl_name)\n",
    "    with open(save_pickle_path, 'wb') as f:\n",
    "        pickle.dump(res_list, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def clean_results_df(df):\n",
    "    df.columns = [x.replace('_', ' ').title() for x in df.columns]\n",
    "    for col_num in range(4,9):\n",
    "        df.iloc[:,col_num] = df.iloc[:,col_num].round(3)\n",
    "    df.loc[:,'Structure'] = vec_clean_cols(df.loc[:,'Structure'])\n",
    "    df.loc[:,'Run Name'] = vec_clean_cols(df.loc[:,'Run Name'])\n",
    "    \n",
    "    \n",
    "def clean_method(method):\n",
    "    methods = ['logr', 'svm', 'xgb', 'rf']\n",
    "    new_name = ['Logistic', 'SVM', 'XGBoost', 'Random Forest']\n",
    "    return new_name[methods.index(method)]\n",
    "\n",
    "def clean_structure_name(structure):\n",
    "    structures = ['Left_wm', 'Right_wm', 'Left_gm', 'Right_gm', 'Right_cerebellum', 'Left_cerebellum', 'Deep_grey']\n",
    "    new_structures = ['Left White Matter', 'Right White Matter', 'Left Grey Matter', 'Right Grey Matter', 'Right Cerebellum', 'Left Cerebellum', 'Deep Grey']\n",
    "    if structure in structures:\n",
    "        return new_structures[structures.index(structure)]\n",
    "    else:\n",
    "        return structure\n",
    "\n",
    "def clean_column_name(name):\n",
    "    name = name.replace('_', ' ').split()\n",
    "    for index in range(len(name)):\n",
    "        if len(name[index]) < 4 and name[index].lower() != 'raw':\n",
    "            name[index] = name[index].upper()\n",
    "        else:\n",
    "            name[index] = name[index].title()\n",
    "    return ' '.join(name)\n",
    "    \n",
    "vec_clean_cols = np.vectorize(clean_column_name)  \n",
    "vec_clean_methods = np.vectorize(clean_method)\n",
    "vec_clean_structure_name = np.vectorize(clean_structure_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18c8ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_text(text, size = 20):\n",
    "    wrap = textwrap.wrap(text, size)\n",
    "    return '\\n'.join(wrap)\n",
    "\n",
    "def color_labels(color_dict, ticks):\n",
    "    for item in ticks:\n",
    "        text = item._text\n",
    "        if text not in color_dict:\n",
    "            continue\n",
    "        item._color = color_dict[text]\n",
    "        \n",
    "            \n",
    "def construct_feature_to_color(features):\n",
    "    colors = ['black', 'red', 'blue', 'green', 'm']\n",
    "    index = 0\n",
    "    switch_index = [3, 19, 43]\n",
    "    color_dict = {}\n",
    "    for enum, feature_name in enumerate(features):\n",
    "        if enum in switch_index:\n",
    "            index+=1\n",
    "        color_dict[feature_name] = colors[index]\n",
    "    return color_dict\n",
    "\n",
    "def clean_feature_names(feature_list, left=False) -> list:\n",
    "    remove_list = ['Original Shape', 'Original Firstorder', 'Original Glcm', 'Original Glrlm']\n",
    "    remove_list = [x.lower() for x in remove_list]\n",
    "    \n",
    "    find_l = ['run', 'variance', 'length', 'level', 'high', 'low', 'mean', 'absolute', \n",
    "              'percentile', 'range', 'priminence', 'shade', 'tendency', 'average', 'entropy',\n",
    "             'probability', 'normalized']\n",
    "    new_list = []\n",
    "    for item in feature_list:\n",
    "        item = item.lower()\n",
    "        for rem in remove_list:\n",
    "            item = item.replace(rem, '')\n",
    "        \n",
    "        for find in find_l:\n",
    "            repl = f' {find} '\n",
    "            item = item.replace(find, repl)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if len(item) < 6:\n",
    "            item = item.upper()\n",
    "        else:\n",
    "            item = item.title()\n",
    "        item = \" \".join(item.split())\n",
    "        new_list.append(item.strip())\n",
    "    if left:\n",
    "        lens = [len(x) for x in new_list]\n",
    "        max_len = max(lens)\n",
    "        new_list = [x.ljust(max_len, ' ') for x in new_list]\n",
    "        return new_list\n",
    "    else:\n",
    "        return new_list\n",
    "    \n",
    "def clean_column_name(name):\n",
    "    name = name.replace('_', ' ').split()\n",
    "    for index in range(len(name)):\n",
    "        if len(name[index]) < 4 and name[index].lower() != 'raw':\n",
    "            name[index] = name[index].upper()\n",
    "        else:\n",
    "            name[index] = name[index].title()\n",
    "    return ' '.join(name)\n",
    "    \n",
    "vec_clean_cols = np.vectorize(clean_column_name)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfec0fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(mobj, number = 10, save_name = None):\n",
    "    mod = mobj.mod\n",
    "    fig = plt.figure(facecolor = 'white', figsize = (10,9))\n",
    "    size_cat = ['Small','Normal', 'Large']\n",
    "    indexes = [0,1, 2]\n",
    "    fig_index = 0\n",
    "    all_colors = []\n",
    "    for index, size in zip(indexes, size_cat):\n",
    "        fig_index+=1\n",
    "        ax = fig.add_subplot(len(indexes),1,fig_index)\n",
    "        ax.set_title(f'Size Class: {size}', fontweight = 'bold', fontsize = 15)\n",
    "        ax.grid(False)\n",
    "        names = mobj.model_features\n",
    "        \n",
    "        fi_all = mm.get_feature_importance(mobj)\n",
    "        if mobj.method == 'RF':\n",
    "            fi = fi_all\n",
    "        else:\n",
    "            fi = fi_all[index]\n",
    "        merge_l = [(name, val) for name, val in zip(names, fi)]\n",
    "        merge_l.sort(key = lambda x: x[1], reverse = True)\n",
    "        x, y = zip(*merge_l)\n",
    "        \n",
    "        x = x[:number]\n",
    "        y = y[:number]\n",
    "        \n",
    "        # make color_dict\n",
    "        feature_struc = mobj.structure\n",
    "        clean_names = [name.replace(feature_struc,'').replace('_', ' ').strip().title() for name in names]\n",
    "        clean_names = clean_feature_names(clean_names)\n",
    "        color_dict = construct_feature_to_color(clean_names)\n",
    "        color_order = list(color_dict.values())\n",
    "        \n",
    "        merge_l = [(col, val) for col, val in zip(color_order, fi)]\n",
    "        merge_l.sort(key = lambda x: x[1], reverse = True)\n",
    "        colors, _ = zip(*merge_l)\n",
    "        colors = colors[:number]\n",
    "        \n",
    "        x = [name.replace(feature_struc,'').replace('_', ' ').strip().title() for name in x]\n",
    "        x = clean_feature_names(x)\n",
    "        x = [wrap_text(name, 18) for name in x]\n",
    "        ax.bar(x, y, width = 0.75)\n",
    "        ax.set_xticklabels(x, ha = 'right', rotation = 50)\n",
    "        all_colors.append(colors)\n",
    "\n",
    "        for item, color in zip(ax._axes.get_xticklabels(), colors):\n",
    "            item._color = color\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    if save_name is not None:\n",
    "        plt.savefig(save_name, dpi = 300)\n",
    "    return all_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcfbe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_heatmaps(mods_l, col_name, save_dir = None, show = True, linewidth = 0.4):\n",
    "    #features = mods_l[0].df.iloc[:-2,:].index.tolist()\n",
    "    features = mods_l[0].mod.feature_names_in_\n",
    "    feature_struc = mods_l[0].structure\n",
    "    features = [x.replace(feature_struc,'').replace('_', ' ').strip().title() for x in features]\n",
    "    features = clean_feature_names(features, False)\n",
    "    size_dict = {0:'Small', 1:'Normal', 2:'Large'}\n",
    "    for size_ind in [0,1,2]:\n",
    "        res_df = pd.DataFrame(index = features)\n",
    "        for enum, mobj in enumerate(mods_l):\n",
    "            fi = mm.get_feature_importance(mobj)\n",
    "            if mobj.method == 'RF':\n",
    "                fi = fi\n",
    "            else:\n",
    "                fi = fi[size_ind]\n",
    "            res_df.insert(0, clean_column_name(mobj.__dict__[col_name]), fi)\n",
    "\n",
    "        norm_df = (res_df/res_df.sum(axis=0))\n",
    "\n",
    "        fig = plt.figure(facecolor = 'white', dpi = 200, figsize = (5,9))\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax = sns.heatmap(norm_df, cmap = 'Reds', linewidths = linewidth, yticklabels=True)\n",
    "        title = f'Relative Feature Importance for Each {col_name.title()}\\nSize Class: {size_dict[size_ind]}'\n",
    "        centerx = np.mean(ax._axes.get_position().intervalx) * 0.7\n",
    "        fig.suptitle(title, fontsize = 20, fontweight = 'bold', x = centerx, ha = 'center')\n",
    "        labels = [x.get_text() for x in ax.get_xticklabels()]\n",
    "        ax.set_xticklabels(labels, rotation = 45, ha = 'right', fontweight = 'bold', color = 'black')\n",
    "        ax.set_yticklabels(ax.get_yticklabels(), fontweight = 'bold', fontsize = 8)\n",
    "\n",
    "        \n",
    "        colors = ['black', 'red', 'blue', 'green', 'm']\n",
    "        index = 0\n",
    "        switch_index = [3, 19, 43]\n",
    "        for enum, item in enumerate(ax._axes.get_yticklabels()):\n",
    "            if enum in switch_index:\n",
    "                index+=1\n",
    "            item._color = colors[index]\n",
    "\n",
    "        if save_dir is not None:\n",
    "            save_path = os.path.join(save_dir, 'cm1_updated_heatmap_{}_{}_{}.png'.format(linewidth,col_name, size_dict[size_ind]))\n",
    "            plt.savefig(save_path, dpi = 200, bbox_inches = 'tight')\n",
    "        if show:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "    return ax\n",
    "            \n",
    "def save_rf_tree(mobj, save_dir, est_ind = None):\n",
    "    if est_ind is None:    \n",
    "        est_ind = random.randrange(0,mobj.mod.n_estimators+1)\n",
    "        \n",
    "    esti = mobj.mod.estimators_[est_ind]\n",
    "    dot_file = os.path.join(save_dir, 'temp_tree.dot')\n",
    "    export_graphviz(esti, out_file = dot_file, \n",
    "                    feature_names = mobj.model_features,\n",
    "                    class_names = ['small', 'normal', 'large'],\n",
    "                    rounded = True, proportion = False, \n",
    "                    precision = 2, filled = True)\n",
    "    \n",
    "    tree_png = os.path.join(save_dir, '{}_esti_{}_tree.png'.format(mobj.run_name, est_ind))\n",
    "    (graph,) = pydot.graph_from_dot_file(dot_file)\n",
    "    graph.write_png(tree_png)\n",
    "    os.remove(dot_file)\n",
    "    \n",
    "    \n",
    "def color_dict_bar(color_dict, save_path = None):\n",
    "    fig = plt.figure(figsize = (6,3), dpi = 200, facecolor = 'white')\n",
    "    ax = fig.add_subplot(111)\n",
    "    colors = ['black', 'red', 'blue', 'green']\n",
    "    merge_list = [(k,v, c) for (k, v), c in zip(color_dict.items(), colors)]\n",
    "    merge_list.sort(key = lambda x: x[1], reverse = True)\n",
    "    groups, values, colors = zip(*merge_list)\n",
    "    groups = update_group_name(groups)\n",
    "    plt.grid(False)\n",
    "    ax.bar(groups, values, color = colors)\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, dpi = 200, transparent = True)\n",
    "    plt.show()\n",
    "\n",
    "def update_group_name(groups):\n",
    "    original = ['shape', 'firstorder', 'glcm', 'glrlm']\n",
    "    ret_val = ['Shape', 'FirstOrder', 'GLCM', 'GLRLM']\n",
    "    new_group = []\n",
    "    for g in groups:\n",
    "        new_group.append(ret_val[original.index(g)])\n",
    "    return new_group\n",
    "\n",
    "def make_pie_relative(color_dict, save_path = None):\n",
    "    fig = plt.figure(figsize = (2,2), dpi = 200)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.grid(False)\n",
    "    \n",
    "    vals = list(color_dict.values())\n",
    "    vals = [round(x, 3) for x in vals]\n",
    "    labs = list(color_dict.keys())\n",
    "    cols = ['black', 'red', 'blue', 'green']\n",
    "    clean_vals = []\n",
    "    clean_labs = []\n",
    "    clean_cols = []\n",
    "    for v,l,c in zip(vals, labs, cols):\n",
    "        if v != 0:\n",
    "            clean_vals.append(v)\n",
    "            clean_labs.append(l)\n",
    "            clean_cols.append(c)\n",
    "            \n",
    "    patches, texts, _ = ax.pie(clean_vals, colors = clean_cols, explode = [0.01]*len(clean_vals), labeldistance = 1.1,\n",
    "           textprops = {'fontsize':5, 'color':'white', 'fontweight':'bold'}, autopct = '%.0f%%', normalize=False)\n",
    "    \n",
    "    #plt.legend(patches, clean_labs, loc=(0, 0))\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, dpi = 200, transparent = True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2adbaa4",
   "metadata": {},
   "source": [
    "# \n",
    "# Below Actually loads results and then you can choose what you want to visualize\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42af7a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True or False depending on whether you ran all the data or only \n",
    "# half when tuning/training/testing with hyperparams_tuning_and_training\n",
    "load_two_results =  \n",
    "\n",
    "try:\n",
    "    load_two_results\n",
    "    \n",
    "    if load_two_results:\n",
    "        # this is run when combining results\n",
    "        res_dir = ''  # dir where results are stored\n",
    "        dict_0_dir = os.path.join(res_dir, '') \n",
    "        dict_0_pkl = os.path.join(dict_0_dir,'.pkl')\n",
    "\n",
    "        dict_1_dir = os.path.join(res_dir, '')\n",
    "        dict_1_pkl = os.path.join(dict_1_dir,'.pkl')\n",
    "        \n",
    "        with open(dict_0_pkl, 'rb') as f:\n",
    "            dict_0 = pickle.load(f)\n",
    "            \n",
    "        with open(dict_1_pkl, 'rb') as f:\n",
    "            dict_1 = pickle.load(f)\n",
    "            \n",
    "        dict_results = dict_0.copy()\n",
    "        dict_results.update(dict_2)\n",
    "        \n",
    "    else:\n",
    "        # this is run when no combing of results is required\n",
    "        dict_result_locations = '.pkl'\n",
    "        with open(dict_result_locations, 'rb') as f:\n",
    "            dict_results = pickle.load(f)\n",
    "            \n",
    "except Exception as e:\n",
    "    print('Failed to run properly')\n",
    "    print(f'Error: {str(e)}')\n",
    "    \n",
    "            \n",
    "# information portion of dataframe\n",
    "info_df = build_df(dict_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a055dd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# results portion\n",
    "res_df = pd.DataFrame(columns = ['run_name', 'accuracy', 'f1', 'recall', 'precision', 'auroc'])\n",
    "for k,v in merge_dict.items():\n",
    "    df_type, phrase, model_method, clf, runtime, test_x, test_y = v\n",
    "    res = pd.Series(get_scores(k, clf, test_x, test_y, 'dict')).to_frame().T\n",
    "    res_df = pd.concat([res_df, res], ignore_index = True, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e151e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate DF dictionary\n",
    "# this is to get access to the full df \n",
    "\n",
    "data_loc = locations.get_locations('data_csv_loc')\n",
    "data = pd.read_csv(data_loc, sep=',', header = 0, index_col = 0)\n",
    "scaled_data = df_methods.scale_df(data)  \n",
    "dfs, sdfs = df_methods.setup_data(data, scaled_data)\n",
    "bdfs, sbdfs = df_methods.balance_data(dfs, sdfs)\n",
    "phrases = general_methods.return_phrases()\n",
    "\n",
    "model_names = ['rf', 'logr', 'svm', 'xgb']\n",
    "merge_df_lists = [sbdfs, bdfs]\n",
    "df_dict = {}\n",
    "df_obs = []\n",
    "cv_seed = 1234\n",
    "\n",
    "df_types = ['Scaled_balanced', 'balanced']\n",
    "for df_list, df_type in zip(merge_df_lists, df_types):\n",
    "    for df, phrase in zip(df_list, phrases):\n",
    "        df_obs.append(df.shape[1])\n",
    "        df = df.T\n",
    "        x,y = df.iloc[:, :-2], df.iloc[:, -1]\n",
    "        y = y+1 #xgb needs positive class values\n",
    "        train_x, test_x, train_y, test_y = train_test_split(x,y, train_size = 0.8, random_state = cv_seed)\n",
    "        for model_method in model_names:\n",
    "            model_name_string = f'{df_type}_{phrase}_{model_method}'\n",
    "            df_dict[model_name_string] = (df.T, x, y, train_x, test_x, train_y, test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74093c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df = pd.concat([info_df, res_df], axis = 1)\n",
    "combine_df.insert(combine_df.shape[1], 'model_id', [x for x in range(len(combine_df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0642593a",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_run = False\n",
    "list_missing = not(pickle_exists())\n",
    "    \n",
    "if re_run or list_missing:\n",
    "    print('Building list...')\n",
    "    model_list = []\n",
    "    for enum,((lab, data), (k1,v1), (k2, v2)) in enumerate(zip(combine_df.iloc[:, :].iterrows(), merge_dict.items(), df_dict.items())):\n",
    "        df_type, phrase, model_method, clf, runtime, test_x, test_y = v1\n",
    "        mod = model()\n",
    "        mod.mod = clf.best_estimator_\n",
    "        mod.accuracy = data.accuracy\n",
    "        mod.f1 = data.f1\n",
    "        mod.precision = data.precision\n",
    "        mod.recall = data.recall\n",
    "        mod.avg_score = np.mean([data.accuracy, data.f1, data.precision, data.recall])\n",
    "        mod.run_name = k1\n",
    "        mod.method = data.model_method\n",
    "        mod.structure = phrase\n",
    "        mod.model_id = data.model_id\n",
    "        mod.auroc = data.auroc\n",
    "        mod.df = v2[0]\n",
    "        mod.model_features = v2[0].index.tolist()[:-2]\n",
    "        if 'Scaled' in k:\n",
    "            mod.df_name = 'scaled'\n",
    "        else:\n",
    "            mod.df_name = 'scaled_balanced'\n",
    "        model_list.append(mod)\n",
    "        \n",
    "    result_list = model_results(model_list)\n",
    "    result_list.sort_results(print_res = False)     \n",
    "    save_pickle(result_list)    \n",
    "        \n",
    "else:\n",
    "    print('Loading list...')\n",
    "    result_list = load_pickle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617fc552",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_models = result_list.top_per_method()\n",
    "method_results = model_results(method_models)\n",
    "method_result_df = method_results.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6845732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_models = result_list.top_per_feature()\n",
    "structure_results = model_results(structure_models)\n",
    "structure_result_df = structure_results.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bcce6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Clean up and save top performing structure and method results to excel\n",
    "\n",
    "\n",
    "feature_df = structure_result_df.copy()\n",
    "method_df = method_result_df.copy()\n",
    "\n",
    "drop_list = ['run_name', 'df_name', 'model_id', 'avg_score', 'auroc']\n",
    "\n",
    "feature_table_df = feature_df.drop(drop_list, axis = 1, inplace = False)\n",
    "methods_table_df = method_df.drop(drop_list, axis = 1, inplace = False)\n",
    "#all_table_df = res_df.drop(['run_name', 'df_name', 'model_id', 'avg_score'], axis = 1, inplace = False)\n",
    "\n",
    "feature_table_df.loc[:,'method'] = vec_clean_methods(feature_table_df.loc[:,'method'])\n",
    "methods_table_df.loc[:,'method'] = vec_clean_methods(methods_table_df.loc[:,'method'])\n",
    "#all_table_df.loc[:,'meethod'] = vec_clean_methods(all_table_df.loc[:,'method'])\n",
    "\n",
    "feature_table_df.loc[:,'structure'] = vec_clean_structure_name(feature_table_df.loc[:,'structure'])\n",
    "methods_table_df.loc[:,'structure'] = vec_clean_structure_name(methods_table_df.loc[:,'structure'])\n",
    "#all_table_df.loc[:,'structure'] = vec_clean_structure_name(all_table_df.loc[:,'structure'])\n",
    "\n",
    "feature_table_df = feature_table_df.rename({\"method\": \"Classifier Method\"}, axis = 1)\n",
    "methods_table_df = methods_table_df.rename({\"method\": \"Classifier Method\"}, axis = 1)\n",
    "#all_table_df = all_table_df.rename({\"method\": \"Classifier Method\"}, axis = 1)\n",
    "\n",
    "\n",
    "feature_table_df.columns = [x.title() for x in feature_table_df.columns]\n",
    "methods_table_df.columns = [x.title() for x in methods_table_df.columns]\n",
    "\n",
    "feature_table_df.iloc[:,2:] = feature_table_df.iloc[:,2:].round(3)\n",
    "methods_table_df.iloc[:,2:] = methods_table_df.iloc[:,2:].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db04348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_save_dir = locations.get_locations('excel_results')\n",
    "save_date_string = locations.get_locations('save_date')\n",
    "for df, name in zip([feature_table_df, methods_table_df], ['features', 'methods', 'all']):\n",
    "    save_path = os.path.join(excel_save_dir, f'New_{save_date_string}_{name}_table_version.xlsx')\n",
    "    df.to_excel(save_path, index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266fb505",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print best performing models by category\n",
    "head_num = 5\n",
    "for colname in combine_df.columns[5:]:\n",
    "    print(colname)\n",
    "    display(combine_df.sort_values(colname, axis = 0, ascending = False).head(head_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cffdfd",
   "metadata": {},
   "source": [
    "# \n",
    "# Confusion matrix\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a893cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can choose whichever one works best for you\n",
    "cm1 = mcol.LinearSegmentedColormap.from_list(\"MyCmapName\",['w', 'w', 'y', 'y', 'orange','orange', 'r', 'r', 'maroon'])\n",
    "cm2 = mcol.LinearSegmentedColormap.from_list(\"MyCmapName\",['w', 'y', 'orange', 'r', 'maroon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e148d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find what ever model object you'd like and unpack it. \n",
    "res = find_entry(9)\n",
    "df_type, phrase, model_method, clf, runtime, test_x, test_y = res[1]\n",
    "run_name = res[0]\n",
    "model = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dadb60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y = model.predict(test_x)\n",
    "cnf_matrix = metrics.confusion_matrix(test_y, predict_y)\n",
    "save_dir = locations.get_locations('confusion_matrix')\n",
    "title = f'confusion_{run_name}'\n",
    "save_path = os.path.join(save_dir + title)\n",
    "pm.plot_matrix(cnf_matrix, save_dir = save_dir, title = title, disp = True, cmap = cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dc0194",
   "metadata": {},
   "source": [
    "# \n",
    "# AUROC\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd140e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find what ever model object you'd like and unpack it. \n",
    "res = find_entry(9)\n",
    "df_type, phrase, model_method, clf, runtime, test_x, test_y = res[1]\n",
    "run_name = res[0]\n",
    "model = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8afa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'default' #whatever you'd like \n",
    "roc_dir = locations.get_locations('ROC_dir')\n",
    "pm.plot_yellowbrick_roc_xy(model, test_x, test_y, title, save_path = roc_dir, disp = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b158f0f6",
   "metadata": {},
   "source": [
    "# \n",
    "# Feature Importance\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d04d626",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_model = result_list.get_model(9)\n",
    "save_dir = locations.get_locations('importance_dir')\n",
    "bar_title = os.path.join(save_dir, 'bar_plots.png')\n",
    "colors_list = feature_importance(figure_model, save_name = bar_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02aa6c95",
   "metadata": {},
   "source": [
    "# \n",
    "# Realtive Feature Importance by Class\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f42eee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_model = result_list.get_model(9)\n",
    "features = figure_model.model_features\n",
    "\n",
    "#Need to remove feature_name and category from features before running\n",
    "# I.e. rem_name = 'Left_wm_original_'\n",
    "rem_name = '' \n",
    "\n",
    "features = [x.replace(rem_name, '') for x in features]\n",
    "group_dict = {'shape': 'shape', 'firstorder': 'firstorder', 'glcm':'glcm', 'glrlm': 'glrlm'}\n",
    "feature_dict = {}\n",
    "for feat in features:\n",
    "    prefix = feat.split('_')[0]\n",
    "    if prefix in group_dict:\n",
    "        feature_dict[feat] = group_dict[prefix]\n",
    "\n",
    "def calc_group_fi(tup_list):\n",
    "    group_rfi_dict = {}\n",
    "    for tup in tup_list:\n",
    "        if tup[1] in group_rfi_dict:\n",
    "            group_rfi_dict[tup[1]]+= tup[2]\n",
    "        else:\n",
    "            group_rfi_dict[tup[1]] = tup[2]\n",
    "\n",
    "    return group_rfi_dict\n",
    "    \n",
    "def return_tup_list(fi_list, feature_dict):\n",
    "    tup_list = []\n",
    "    for imp, (feature_name, feature_group) in zip(fi_list, feature_dict.items()):\n",
    "        tup_list.append((feature_name, feature_group, imp))\n",
    "    return tup_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc288d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_model = result_list.get_model(9)\n",
    "fi = mm.get_feature_importance(figure_model)\n",
    "relative_fi = []\n",
    "color_dicts = []\n",
    "for i in range(len(fi)):\n",
    "    rfi = list(fi[i]/fi[i].sum(axis = 0))\n",
    "    relative_fi.append(rfi)\n",
    "    tup_list = return_tup_list(rfi, feature_dict)\n",
    "    color_dict = calc_group_fi(tup_list)\n",
    "    color_dicts.append(color_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c685c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = ['glcm', 'glrlm', 'firstorder', 'shape']\n",
    "colors = '#4d5ce3', '#73d461', '#cc434c', 'black'\n",
    "fig = plt.figure(facecolor = 'white', figsize = (6,2), dpi = 200)\n",
    "ax = fig.add_subplot(111)\n",
    "sizes = ['Large', 'Normal', 'Small']\n",
    "text_color = 'white'\n",
    "prev_sm, prev_nm, prev_lg = 0, 0, 0\n",
    "for group, color in zip(order, colors):\n",
    "    sm = color_dicts[0][group]\n",
    "    nm = color_dicts[1][group]\n",
    "    lg = color_dicts[2][group]\n",
    "    #vals = [sm, nm, lg]\n",
    "    vals = [lg, nm, sm]\n",
    "    #bottoms = [prev_sm, prev_nm, prev_lg]\n",
    "    bottoms = [prev_lg, prev_nm, prev_sm]\n",
    "    container = ax.barh(sizes, vals, color = color, left = bottoms)\n",
    "    \n",
    "    percents = np.round([x*100 for x in [sm, nm, lg]]).astype(int)\n",
    "    percents = [str(x) + '%' if x > 3 else '' for x in percents] #Change >3 to get additional percentage values to show up.\n",
    "    \n",
    "    text_l = ax.bar_label(container, percents, label_type = 'center', color = text_color, fontsize = 8, padding = 0, weight = 'extra bold')\n",
    "        \n",
    "    prev_sm = sm + prev_sm\n",
    "    prev_nm = nm + prev_nm\n",
    "    prev_lg = lg + prev_lg\n",
    "\n",
    "ax.set_yticklabels(sizes, fontweight = 'bold', color = 'black')\n",
    "\n",
    "ax.set_xlabel('Relative Importance (%)', fontsize = 10, fontweight = 'bold', color = 'black')\n",
    "save_dir = locations.get_locations('save_dir')\n",
    "save_path = os.path.join('category_relative_importance.png')\n",
    "plt.savefig(save_path, dpi = 500, bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb1f903",
   "metadata": {},
   "source": [
    "# \n",
    "# Heatmaps\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb9ac8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "method_models = result_list.top_per_method()\n",
    "structure_models = result_list.top_per_feature()\n",
    "\n",
    "hm_dir = locations.get_locations('heatmaps')\n",
    "os.makedirs(hm_dir, exist_ok = True)\n",
    "\n",
    "ax = build_heatmaps(structure_models, 'structure', save_dir = hm_dir, show = True, linewidth = .4)\n",
    "ax = build_heatmaps(method_models, 'method', save_dir = hm_dir, show = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416bc035",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
