{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f04be3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import math, os, sys, math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import textwrap\n",
    "from scipy import stats\n",
    "import re\n",
    "\n",
    "code_dir = '/'.join(os.getcwd().split('/')[:-1])\n",
    "main_code = os.path.join(code_dir, 'main_code')\n",
    "\n",
    "sys.path.append(main_code)\n",
    "import locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609f270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting methods\n",
    "\n",
    "def plot_distributions(start, num, df, save_path = None, disp = False):\n",
    "    total_row = math.ceil(num/3)\n",
    "    fig_length = total_row * 1.25\n",
    "    fig = plt.figure(figsize = (4, fig_length),facecolor = 'white', dpi = 300)\n",
    "    \n",
    "    for i in range(num):\n",
    "        row = i + start\n",
    "        ax = fig.add_subplot(total_row, 3, i+1)\n",
    "\n",
    "        y_neg = (df.loc[:,df.iloc[-1,:] == -1]).iloc[row, :]\n",
    "        y_norm = (df.loc[:,df.iloc[-1,:] == 0]).iloc[row, :]\n",
    "        y_large = (df.loc[:,df.iloc[-1,:] == 1]).iloc[row, :]\n",
    "        \n",
    "        mean_series = pd.concat([y_neg, y_norm, y_large])\n",
    "        num_size = len(str(int(np.mean(mean_series))))\n",
    "    \n",
    "        if num_size > 4:\n",
    "            div = 10**num_size\n",
    "            y_neg = y_neg/div\n",
    "            y_norm = y_norm/div\n",
    "            y_large = y_large/div\n",
    "        for  data, color, lab in zip([y_neg, y_norm, y_large], ['red', 'grey', 'blue'], ['Small', 'Normal', 'Large']):\n",
    "            ax = sns.kdeplot(data, color = color, alpha = 0.4, shade = True, legend = lab, linewidth = 0.3)\n",
    "            ax.set_title('test')\n",
    "            ax.set(xlabel = None)\n",
    "            ax.set(ylabel = None)\n",
    "            \n",
    "            title = df.index[row].replace('_', ' ').title()\n",
    "            t_l = title.split(' ')[4:]\n",
    "            title = ' '.join(t_l)\n",
    "            title = textwrap.fill(title, 20)\n",
    "\n",
    "            #fig.suptitle(title, ha = 'center', size = 20, weight = 'bold')\n",
    "            #fig.tight_layout(rect=[0, 0.03, 1, 0.90])\n",
    "            font_dict = {'ha':'center', 'fontsize':5, 'fontweight':'normal'}\n",
    "            ax.axes.yaxis.set_visible(False)\n",
    "            ax.set_title(title, fontdict = font_dict)\n",
    "\n",
    "\n",
    "            for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "                label.set_fontsize(5)\n",
    "    \n",
    "    custom_lines = [Line2D([0], [0], color='red', lw=4),\n",
    "                    Line2D([0], [0], color='grey', lw=4),\n",
    "                    Line2D([0], [0], color='blue', lw=4)]\n",
    "    \n",
    "    fig_title = ' '.join(df.index[row].replace('_', ' ').title().split(' ')[:4])\n",
    "    fig.suptitle(fig_title, va = 'top', fontsize = 15)\n",
    "    fig.legend(custom_lines, ['Small', 'Normal', 'Large'], loc = 'upper right',  fontsize = 3 )#, bbox_to_anchor=(0.48, 0.93))\n",
    "    plt.tight_layout(rect=[0, 0, 0.95, 0.94])\n",
    "    \n",
    "    if save_path is not None:\n",
    "        out_file = os.path.join(save_path, fig_title.replace(' ', '_') + '.png')\n",
    "        plt.savefig(out_file, format = 'png', dpi = 300, bbox_inches = 'tight')\n",
    "    if save_path is None or disp:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "def plot_all_dist(df, save_path = None, disp = False):\n",
    "    lens = [0, 0, 0, 0]\n",
    "    for enum, name in enumerate(df.index):\n",
    "        if '_shape_' in name:\n",
    "            lens[0]+=1\n",
    "        elif '_firstorder_' in name:\n",
    "            lens[1]+=1\n",
    "        elif '_glcm_' in name:\n",
    "            lens[2]+=1\n",
    "        elif '_glrlm_' in name:\n",
    "            lens[3]+=1\n",
    "    start = 0\n",
    "    for l in lens:\n",
    "        if l == 0:\n",
    "            continue\n",
    "        plot_distributions(start, l ,df, save_path, disp)\n",
    "        start+=l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a008fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other methods\n",
    "\n",
    "def summary_df(df, save_name = None):\n",
    "    summary_dict = {'Mean':df.mean(axis=1), 'Std_Dev':df.std(axis=1),'Min':df.min(axis=1),\n",
    "                    'Max':df.max(axis=1)}\n",
    "    \n",
    "    summary_df = pd.DataFrame.from_dict(summary_dict)\n",
    "    if save_name is not None:\n",
    "        summary_df.to_excel(save_name, index = True, header = True, engine = 'openpyxl')\n",
    "\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491805a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations.get_locations('result_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcb8c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup directories and Load DataFrame\n",
    "\n",
    "storage_dir = locations.get_locations('result_dir')\n",
    "save_date = locations.get_locations('save_date')\n",
    "csv_file = f'{save_date}_home_results.csv'\n",
    "data_loc = os.path.join(storage_dir, csv_file)\n",
    "save_dir = locations.get_locations('save_dir')\n",
    "\n",
    "data = pd.read_csv(data_loc, sep=',', header = 0, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da86618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = ['Deep_grey', 'Brain_stem', 'Left_wm', 'Left_gm', \n",
    "           'Right_wm', 'Right_gm', 'Left_cerebellum', 'Right_cerebellum']\n",
    "\n",
    "def setup_data(data):\n",
    "    row_nums = []\n",
    "    dfs = []\n",
    "\n",
    "    # seperate df's into structure specific dfs\n",
    "    for p in phrases:\n",
    "        ind_list = []\n",
    "        for enum, n in enumerate(data.index):\n",
    "            if p in n:\n",
    "                ind_list.append(enum)\n",
    "        row_nums.append((p, ind_list))\n",
    "        df = data.iloc[ind_list,:]\n",
    "\n",
    "        dfs.append(df)\n",
    "        \n",
    "    return dfs\n",
    "        \n",
    "dfs = setup_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149f12d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show summary of df's - mean, std-dev, min and max\n",
    "out_dir = locations.get_locations('excel_results')\n",
    "out_xcell = os.path.join(out_dir, 'cleaned_summary_statistics.xlsx')\n",
    "with pd.ExcelWriter(out_xcell) as writer:\n",
    "    for d, p in zip(dfs, phrases):\n",
    "        for i, name in zip([-1, 0, 1], ['Small', 'Normal', 'Large']):\n",
    "            #print(\"{}:\".format(name))\n",
    "            sheet_name = p + '_' + name\n",
    "            #print(sheet_name)\n",
    "            res = summary_df((d.loc[:,d.iloc[-1,:] == i]).iloc[:-2, :])\n",
    "            res.to_excel(writer, sheet_name = sheet_name, index = True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d3314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_title(title, wrap = True):\n",
    "    title = title.replace('\\n', '')\n",
    "    s_l = title.split('_')\n",
    "    ind = 0\n",
    "    for enum, s in enumerate(s_l):\n",
    "        if s == 'original':\n",
    "            ind = enum + 1\n",
    "            break\n",
    "            \n",
    "    if s_l[ind] == 'firstorder':\n",
    "        s_l[ind] = 'FO'\n",
    "    if wrap:\n",
    "        return textwrap.fill(' '.join(s_l[ind:]), 20)\n",
    "    else:\n",
    "        return ' '.join(s_l[ind:])\n",
    "\n",
    "df_all = dfs[0].copy().reset_index().iloc[:-2, :]\n",
    "df_all = df_all.drop('index', axis = 1)\n",
    "clean_ind = dfs[0].index.tolist()[:-2]\n",
    "clean_ind = [clean_title(x) for x in clean_ind]\n",
    "\n",
    "for df in dfs[1:]:\n",
    "    df = df.copy().reset_index().iloc[:-2,:]\n",
    "    df = df.drop('index', axis = 1)\n",
    "    df_all = df_all.add(df)\n",
    "\n",
    "df_all.index = pd.Series(clean_ind)\n",
    "save_path = os.path.join(out_dir, 'all_summary.xlsx')\n",
    "summary_df(df_all, save_name = save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b427ae94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dist_folder = os.path.join(storage_dir , 'distribution_figures')\n",
    "os.makedirs(dist_folder, exist_ok = True)\n",
    "\n",
    "raw_dist_folder = os.path.join(dist_folder, 'raw_data')\n",
    "os.makedirs(raw_dist_folder, exist_ok = True)\n",
    "plot_all_dist(dfs[0], raw_dist_folder, disp = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dfa8b5",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "### Remove features that are basically size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3949650",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "del_names = []\n",
    "del_inds = []\n",
    "\n",
    "keep_names = []\n",
    "keep_inds = []\n",
    "\n",
    "for df in dfs:\n",
    "    small = df.loc[:,data.iloc[-1,:] == -1].iloc[:,1:100]\n",
    "    norm = df.loc[:,data.iloc[-1,:] == 0].iloc[:,1:100]\n",
    "    large = df.loc[:,data.iloc[-1,:] == 1].iloc[:,1:100]\n",
    "    for enum, i in enumerate(df.index[:-2]):\n",
    "        i_small = small.loc[i,:]\n",
    "        i_norm = norm.loc[i,:]\n",
    "        i_large = large.loc[i,:]\n",
    "        res = stats.f_oneway(i_small, i_norm, i_large)\n",
    "        f_val, p_val = stats.f_oneway(i_small, i_norm, i_large)\n",
    "        p = re.compile('original', re.I)\n",
    "        m = p.search(i)\n",
    "        if p_val < 5e-15:\n",
    "            #print(\"{:>6.2f}\\t{:>5.2f}: {}\".format(f_val, p_val, i))    \n",
    "            del_names.append(i[m.end()+1:].strip())\n",
    "            del_inds.append(enum)\n",
    "        else:\n",
    "            keep_names.append(i[m.end()+1:].strip())\n",
    "            keep_inds.append(enum)\n",
    "\n",
    "del_names = list(set(del_names))\n",
    "del_inds = list(set(del_inds))\n",
    "keep_names = list(set(keep_names))\n",
    "keep_inds = list(set(keep_inds))\n",
    "\n",
    "print(\"Del Names:{}\\nDel Inds:{}\\nKeep Names:{}\\nKeep Inds: {}\".format(len(del_names),len(del_inds),len(keep_names),len(keep_inds)))\n",
    "            \n",
    "            \n",
    "data_rem_names = []\n",
    "data_keep_names = []\n",
    "for i in data.index:\n",
    "    p = re.compile('original', re.I)\n",
    "    m = p.search(i)\n",
    "    try:\n",
    "        i_short = i[m.end()+1:].strip()\n",
    "    except:\n",
    "        continue\n",
    "    if i_short in del_names:\n",
    "        data_rem_names.append(i)\n",
    "    else:\n",
    "        data_keep_names.append(i)\n",
    "\n",
    "        \n",
    "        \n",
    "# Drop features and remake cleaned dfs\n",
    "# then plot figures to see that we're happy. \n",
    "\n",
    "clean_data = data.drop(data_rem_names, axis = 0)\n",
    "clean_dfs = setup_data(clean_data)\n",
    "\n",
    "dist_folder = os.path.join(storage_dir , 'distribution_figures')\n",
    "clean_dist_folder = os.path.join(dist_folder, 'cleaned_data')\n",
    "os.makedirs(clean_dist_folder, exist_ok = True)\n",
    "\n",
    "plot_all_dist(clean_dfs[0], clean_dist_folder, disp = True)\n",
    "\n",
    "print(\"Following have been dropped\")\n",
    "\n",
    "dirty_data = data.drop(data_keep_names, axis = 0)\n",
    "dirty_dfs = setup_data(dirty_data)\n",
    "\n",
    "dirty_dist_folder = os.path.join(dist_folder, 'dirty_data')\n",
    "os.makedirs(dirty_dist_folder, exist_ok = True)\n",
    "\n",
    "plot_all_dist(dirty_dfs[0], dirty_dist_folder, disp = True)\n",
    "\n",
    "save_date = locations.get_locations('save_date')\n",
    "clean_save_name = f'{save_date}_clean_data.csv'\n",
    "dirty_save_name = f'{save_date}_dirty_data.csv'\n",
    "\n",
    "save_loc_clean = os.path.join(storage_dir, clean_save_name)\n",
    "clean_data.to_csv(save_loc_clean, sep = ',', header = True, index=True)\n",
    "\n",
    "save_loc_dity = os.path.join(storage_dir, dirty_save_name)\n",
    "dirty_data.to_csv(save_loc_dity, sep = ',', header = True, index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
